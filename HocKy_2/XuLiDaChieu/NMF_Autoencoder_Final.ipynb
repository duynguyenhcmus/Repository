{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMF_Autoencoder_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqPW4XRUmhAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9bdea82-151a-499c-f93a-c208de1d2b7a"
      },
      "source": [
        "!pip install torchnmf\n",
        "#Implement libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable as V\n",
        "from sklearn.decomposition import NMF\n",
        "import torchnmf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchnmf in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchnmf) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from torchnmf) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->torchnmf) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->torchnmf) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFH9Rx6TngG3"
      },
      "source": [
        "#Implement Nonnegative Matrix Factorization\n",
        "X = np.array([[1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1]])\n",
        "model = NMF(n_components=2, init='random', random_state=0)\n",
        "W = model.fit_transform(X)\n",
        "H = model.components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-5khqbupnn3",
        "outputId": "2b650bb9-f00b-41dd-dcb1-51153888aeed"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiLuVhD1pj2p",
        "outputId": "0dcab9f0-c228-4aae-ea11-8a413f633b57"
      },
      "source": [
        "print(W)\n",
        "print(W.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46243941]\n",
            " [0.56287245 0.37784392]\n",
            " [1.12677624 0.29266953]\n",
            " [1.69067649 0.20749713]\n",
            " [2.25458746 0.12231871]\n",
            " [2.81849147 0.0371442 ]]\n",
            "(6, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ9mhvtlplqN",
        "outputId": "d054344c-0ad1-4bd0-c8ce-0b8fad54f0f4"
      },
      "source": [
        "H"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.10033104, 0.32627035],\n",
              "       [2.16343685, 2.16145298]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz4F8OsipxVY",
        "outputId": "0fb2cc17-5f7d-41d1-e227-eec0a589b822"
      },
      "source": [
        "print(np.matmul(W,H))\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.00045845 0.99954104]\n",
            " [1.99965992 1.00034045]\n",
            " [2.99977515 1.0002251 ]\n",
            " [3.99988724 1.00011289]\n",
            " [5.00000882 0.99999117]\n",
            " [6.00012424 0.99987563]]\n",
            "[[1 1]\n",
            " [2 1]\n",
            " [3 1]\n",
            " [4 1]\n",
            " [5 1]\n",
            " [6 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B27mga8KGLDF"
      },
      "source": [
        "W=torch.tensor([[1, 4], [2, 4], [3, 3], [3, 2], [4, 2], [6, 1]],dtype=torch.float32,requires_grad=True)\n",
        "x=torch.tensor(X.astype(np.float32))\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self,w=W):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.w=w\n",
        "        #Encoder\n",
        "        self.encoder=nn.Linear(6,2,bias=False)\n",
        "        \n",
        "        #Decoder \n",
        "        self.decoder=nn.Linear(2,6,bias=False)\n",
        "        self.encoder.weight=nn.Parameter((torch.linalg.pinv(self.w)))\n",
        "        self.decoder.weight=nn.Parameter(self.w)\n",
        "        \n",
        "    def forward(self,x):\n",
        "      encode=torch.relu(self.encoder(x.T))\n",
        "      decode=self.decoder(encode)\n",
        "      return self.w, encode, decode.T\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWdzm8UoHwn2",
        "outputId": "a0b82a8c-ac8b-427b-e2ce-eb4c63c93b6f"
      },
      "source": [
        "model_1=AutoEncoder()\n",
        "total_loss=[]\n",
        "list_para=[]\n",
        "list_h=[]\n",
        "list_w=[]\n",
        "optimizer=torch.optim.Adam(model_1.parameters(),lr=1e-4,weight_decay=1e-3,eps=1e-4, betas=(0.90,0.99))\n",
        "for i in range(5000):\n",
        "  w_pred, h_pred,x_pred=model_1(x)\n",
        "  loss=torchnmf.metrics.kl_div(x_pred,x)\n",
        "  if torch.isnan(loss):\n",
        "    break\n",
        "  else:\n",
        "    total_loss.append(loss)\n",
        "    list_para.append(x_pred)\n",
        "    list_h.append(h_pred)\n",
        "    list_w.append(w_pred)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print('best loss: ',np.min(total_loss))\n",
        "print('x to predict: \\n',x)\n",
        "print('best x_pred: \\n',list_para[np.argmin(total_loss)])\n",
        "print('best h_pred: \\n',list_h[np.argmin(total_loss)])\n",
        "print('best w_pred: \\n',list_w[np.argmin(total_loss)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best loss:  tensor(0.0302, grad_fn=<AddBackward0>)\n",
            "x to predict: \n",
            " tensor([[1., 1.],\n",
            "        [2., 1.],\n",
            "        [3., 1.],\n",
            "        [4., 1.],\n",
            "        [5., 1.],\n",
            "        [6., 1.]])\n",
            "best x_pred: \n",
            " tensor([[1.0071, 0.9966],\n",
            "        [1.8790, 1.0274],\n",
            "        [2.9975, 0.9849],\n",
            "        [3.7391, 1.0206],\n",
            "        [4.8588, 1.0691],\n",
            "        [6.3634, 1.0616]], grad_fn=<PermuteBackward>)\n",
            "best h_pred: \n",
            " tensor([[1.1230, 0.0000],\n",
            "        [0.1628, 0.2060]], grad_fn=<ReluBackward0>)\n",
            "best w_pred: \n",
            " tensor([[0.8328, 3.9460],\n",
            "        [1.5532, 3.4652],\n",
            "        [2.4738, 2.4777],\n",
            "        [3.5259, 2.4720],\n",
            "        [4.5178, 1.5717],\n",
            "        [5.4667, 0.6612]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}